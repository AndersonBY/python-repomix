"""
Skill Generation Module - Generates Claude Agent Skills from codebase
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional
from pathlib import Path
import re

from ...shared.logger import logger
from ...config.config_schema import RepomixConfig
from ..file.file_types import ProcessedFile


@dataclass
class SkillReferences:
    """References for skill output - each becomes a separate file"""

    summary: str
    structure: str
    files: str
    tech_stack: Optional[str] = None


@dataclass
class SkillRenderContext:
    """Context for rendering SKILL.md"""

    skill_name: str
    skill_description: str
    project_name: str
    total_files: int
    total_lines: int
    total_tokens: int
    has_tech_stack: bool
    source_url: Optional[str] = None


@dataclass
class SkillReferencesResult:
    """Result of skill references generation"""

    references: SkillReferences
    skill_name: str
    project_name: str
    skill_description: str
    total_files: int
    total_lines: int
    statistics_section: str
    has_tech_stack: bool
    source_url: Optional[str] = None


def validate_skill_name(name: str) -> str:
    """Validate and normalize skill name

    Args:
        name: Raw skill name

    Returns:
        Normalized skill name (lowercase, hyphens)

    Raises:
        ValueError: If name is invalid
    """
    # Convert to lowercase and replace spaces/underscores with hyphens
    normalized = re.sub(r"[\s_]+", "-", name.lower().strip())
    # Remove any characters that aren't alphanumeric or hyphens
    normalized = re.sub(r"[^a-z0-9-]", "", normalized)
    # Remove consecutive hyphens
    normalized = re.sub(r"-+", "-", normalized)
    # Remove leading/trailing hyphens
    normalized = normalized.strip("-")

    if not normalized:
        raise ValueError(f"Invalid skill name: {name}")

    return normalized


def generate_default_skill_name(root_dirs: List[str]) -> str:
    """Generate default skill name from root directories

    Args:
        root_dirs: List of root directories

    Returns:
        Generated skill name
    """
    if not root_dirs:
        return "codebase"

    # Use the first directory name
    first_dir = Path(root_dirs[0]).name
    return validate_skill_name(first_dir)


def generate_project_name(root_dirs: List[str]) -> str:
    """Generate project name from root directories

    Args:
        root_dirs: List of root directories

    Returns:
        Project name
    """
    if not root_dirs:
        return "Project"

    return Path(root_dirs[0]).name


def generate_skill_description(skill_name: str, project_name: str) -> str:
    """Generate skill description

    Args:
        skill_name: Skill name
        project_name: Project name

    Returns:
        Skill description
    """
    return f"Codebase reference for {project_name}"


def get_skill_template() -> str:
    """Get the template for SKILL.md

    Returns:
        SKILL.md template string
    """
    return """---
name: {skill_name}
description: {skill_description}
---

# {project_name} Codebase Reference

{total_files} files | {total_lines} lines | {total_tokens} tokens

## Overview

Use this skill when you need to:
- Understand project structure and file organization
- Find where specific functionality is implemented
- Read source code for any file
- Search for code patterns or keywords

## Files

| File | Contents |
|------|----------|
| `references/summary.md` | **Start here** - Purpose, format explanation, and statistics |
| `references/project-structure.md` | Directory tree with line counts per file |
| `references/files.md` | All file contents (search with `## File: <path>`) |
{tech_stack_row}

## How to Use

### 1. Find file locations

Check `project-structure.md` for the directory tree:

```
src/
  index.ts (42 lines)
  utils/
    helpers.ts (128 lines)
```

### 2. Read file contents

Grep in `files.md` for the file path:

```
## File: src/utils/helpers.ts
```

### 3. Search for code

Grep in `files.md` for keywords:

```
function calculateTotal
```

## Common Use Cases

**Understand a feature:**
1. Search `project-structure.md` for related file names
2. Read the main implementation file in `files.md`
3. Search for imports/references to trace dependencies

**Debug an error:**
1. Grep the error message or class name in `files.md`
2. Check line counts in `project-structure.md` to find large files

**Find all usages:**
1. Grep function or variable name in `files.md`

## Tips

- Use line counts in `project-structure.md` to estimate file complexity
- Search `## File:` pattern to jump between files
- Check `summary.md` for excluded files, format details, and file statistics
{tech_stack_tip}

---

This skill was generated by [Repomix](https://github.com/andersonby/python-repomix){source_info}
"""


def generate_skill_md(context: SkillRenderContext) -> str:
    """Generate SKILL.md content

    Args:
        context: Render context

    Returns:
        SKILL.md content
    """
    template = get_skill_template()

    tech_stack_row = ""
    tech_stack_tip = ""
    if context.has_tech_stack:
        tech_stack_row = "| `references/tech-stack.md` | Languages, frameworks, and dependencies |"
        tech_stack_tip = "- Check `tech-stack.md` for languages, frameworks, and dependencies"

    source_info = ""
    if context.source_url:
        source_info = f" from [{context.project_name}]({context.source_url})"

    return template.format(
        skill_name=context.skill_name,
        skill_description=context.skill_description,
        project_name=context.project_name,
        total_files=context.total_files,
        total_lines=context.total_lines,
        total_tokens=context.total_tokens,
        tech_stack_row=tech_stack_row,
        tech_stack_tip=tech_stack_tip,
        source_info=source_info,
    ).strip() + "\n"


def calculate_statistics(
    processed_files: List[ProcessedFile],
    file_line_counts: Dict[str, int],
) -> Dict[str, int]:
    """Calculate statistics for skill output

    Args:
        processed_files: List of processed files
        file_line_counts: Line counts per file

    Returns:
        Statistics dictionary
    """
    total_files = len(processed_files)
    total_lines = sum(file_line_counts.values())

    return {
        "total_files": total_files,
        "total_lines": total_lines,
    }


def generate_statistics_section(statistics: Dict[str, int]) -> str:
    """Generate statistics section for summary

    Args:
        statistics: Statistics dictionary

    Returns:
        Statistics section string
    """
    return f"""## Statistics

- Total Files: {statistics['total_files']}
- Total Lines: {statistics['total_lines']}
"""


def detect_tech_stack(processed_files: List[ProcessedFile]) -> Optional[Dict[str, List[str]]]:
    """Detect technology stack from processed files

    Args:
        processed_files: List of processed files

    Returns:
        Tech stack dictionary or None if not detected
    """
    languages: Dict[str, int] = {}
    frameworks: List[str] = []

    for file in processed_files:
        ext = Path(file.path).suffix.lower()
        if ext:
            lang = _ext_to_language(ext)
            if lang:
                languages[lang] = languages.get(lang, 0) + 1

        # Detect frameworks from file content
        content_lower = file.content.lower()
        if "import react" in content_lower or "from react" in content_lower:
            if "React" not in frameworks:
                frameworks.append("React")
        if "import vue" in content_lower or "from vue" in content_lower:
            if "Vue" not in frameworks:
                frameworks.append("Vue")
        if "import django" in content_lower or "from django" in content_lower:
            if "Django" not in frameworks:
                frameworks.append("Django")
        if "import flask" in content_lower or "from flask" in content_lower:
            if "Flask" not in frameworks:
                frameworks.append("Flask")
        if "import fastapi" in content_lower or "from fastapi" in content_lower:
            if "FastAPI" not in frameworks:
                frameworks.append("FastAPI")

    if not languages:
        return None

    # Sort languages by count
    sorted_languages = sorted(languages.items(), key=lambda x: x[1], reverse=True)

    return {
        "languages": [lang for lang, _ in sorted_languages[:5]],
        "frameworks": frameworks[:5] if frameworks else [],
    }


def _ext_to_language(ext: str) -> Optional[str]:
    """Convert file extension to language name"""
    mapping = {
        ".py": "Python",
        ".js": "JavaScript",
        ".ts": "TypeScript",
        ".jsx": "JavaScript",
        ".tsx": "TypeScript",
        ".java": "Java",
        ".go": "Go",
        ".rs": "Rust",
        ".rb": "Ruby",
        ".php": "PHP",
        ".c": "C",
        ".cpp": "C++",
        ".cs": "C#",
        ".swift": "Swift",
        ".kt": "Kotlin",
        ".scala": "Scala",
    }
    return mapping.get(ext)


def generate_tech_stack_md(tech_stack: Dict[str, List[str]]) -> str:
    """Generate tech-stack.md content

    Args:
        tech_stack: Tech stack dictionary

    Returns:
        Tech stack markdown content
    """
    lines = ["# Technology Stack\n"]

    if tech_stack.get("languages"):
        lines.append("## Languages\n")
        for lang in tech_stack["languages"]:
            lines.append(f"- {lang}")
        lines.append("")

    if tech_stack.get("frameworks"):
        lines.append("## Frameworks\n")
        for framework in tech_stack["frameworks"]:
            lines.append(f"- {framework}")
        lines.append("")

    return "\n".join(lines)
